{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "Based on lyrics and the audio features, we will try to predict whether the song will be a hit or not.\n",
    "\n",
    "In order to predict the class based on the lyrics, we have to make numerical representation of the lyrics. We used several techniques for this: TF-IDF, Word2Vec and Doc2Vec.\n",
    "\n",
    "For classification, we used the following machine learning techniques: Logistic Regression, Random Forest, Neural Networks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from gensim.models import Doc2Vec\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import multiprocessing\n",
    "from tqdm import tqdm\n",
    "from sklearn import utils\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import TransformerMixin,BaseEstimator\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import codecs\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "from keras import optimizers\n",
    "import string\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# import warnings filter\n",
    "from warnings import simplefilter\n",
    "# ignore all future warnings\n",
    "simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/top_hits_merged_clean_lyrics_audio_features.json') as json_file:\n",
    "    top_hits = json.load(json_file)\n",
    "    \n",
    "with open('../data/not_hits_merged_clean_lyrics_audio_features.json') as json_file:\n",
    "    not_hits = json.load(json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We assign a class to each song, depending whether the song was on the Billboard 100: \n",
    "- 1 - hit\n",
    "- 0 - not hit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_hits_df = pd.read_json(top_hits)\n",
    "not_hits_df = pd.read_json(not_hits)\n",
    "\n",
    "top_hits_df['class'] = 1\n",
    "not_hits_df['class'] = 0\n",
    "\n",
    "df = pd.concat([top_hits_df, not_hits_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TD-IDF\n",
    "\n",
    "We used the TF-IDF (Term Frequency-Inverse Document Frequency) to vectorize the lyrics. Additionally, we tried dimensionality reduction with PCA to observe whether it will improve the results. \n",
    "\n",
    "TF-IDF is a way of representing how important a particular term is in the context of a given document, based on how many times the term appears and how many other documents that same term appears in. The higher the TF-IDF, the more important that term is to that document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create our list of punctuation marks\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Create our list of stopwords\n",
    "nlp = spacy.load('en')\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "parser = English()\n",
    "\n",
    "# Creating tokenizer function\n",
    "def spacy_tokenizer(sentence):\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    mytokens = parser(sentence)\n",
    "\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "\n",
    "    # Removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['clean_lyrics'] # the features we want to analyze\n",
    "ylabels = df['class'] # the labels, or answers, we want to test against\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3, random_state=72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "\n",
    "We try to predict whether the song will be a hit or not based on lyrics, using Logistic Regression. The test accuracy is 0.54. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test Accuracy: 0.5497220506485485\n",
      " Precision: [0.51548947 0.58374384]\n",
      " Recall: [0.55172414 0.54797688]\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression(solver=\"lbfgs\")\n",
    "\n",
    "# Create pipeline using Bag of Words\n",
    "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "# model generation\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "# Predicting with a test dataset\n",
    "predicted = pipe.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\" test Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(\" Precision:\",metrics.precision_score(y_test, predicted, average=None))\n",
    "print(\" Recall:\",metrics.recall_score(y_test, predicted, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression with PCA\n",
    "\n",
    "We try to predict whether the song will be a hit or not based on lyrics, using Logistic Regression. We use PCA to reduce the dimensionality of the matrix to 50. The test accuracy is 0.57. So, we have an improvement when using Logistic Regression with Principal Component Analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ToDenseTransformer(BaseEstimator,TransformerMixin):\n",
    "\n",
    "    # here you define the operation it should perform\n",
    "    def transform(self, X, y=None, **fit_params):\n",
    "        return X.todense()\n",
    "\n",
    "    # just return self\n",
    "    def fit(self, X, y=None, **fit_params):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test Accuracy: 0.5781346510191476\n",
      " Precision: [0.53854506 0.63037249]\n",
      " Recall: [0.65782493 0.50867052]\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline using Bag of Words\n",
    "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
    "                 ('to_dense',ToDenseTransformer()),\n",
    "                 ('pca',PCA(50)),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "# model generation\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "# Predicting with a test dataset\n",
    "predicted = pipe.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\" test Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(\" Precision:\",metrics.precision_score(y_test, predicted, average=None))\n",
    "print(\" Recall:\",metrics.recall_score(y_test, predicted, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier\n",
    "\n",
    "We try to predict whether the song will be a hit or not based on lyrics, using Random Forest Classifier.The test accuracy is 0.53. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test Accuracy: 0.5379864113650401\n",
      " Precision: [0.50424929 0.56407448]\n",
      " Recall: [0.47214854 0.59537572]\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=1000)\n",
    "\n",
    "# Create pipeline using Bag of Words\n",
    "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "# model generation\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "# Predicting with a test dataset\n",
    "predicted = pipe.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\" test Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(\" Precision:\",metrics.precision_score(y_test, predicted, average=None))\n",
    "print(\" Recall:\",metrics.recall_score(y_test, predicted, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest Classifier with PCA\n",
    "\n",
    "We try to predict whether the song will be a hit or not based on lyrics, using Random Forest Classifier. We use PCA to reduce the dimensionality of the matrix to 50. The test accuracy is 0.50. So, we don't an improvement when using Random Forest Classifier with Principal Component Analysis. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test Accuracy: 0.5046324891908586\n",
      " Precision: [0.46833773 0.53658537]\n",
      " Recall: [0.47082228 0.53410405]\n"
     ]
    }
   ],
   "source": [
    "# Create pipeline using Bag of Words\n",
    "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
    "                 ('to_dense',ToDenseTransformer()),\n",
    "                 ('pca',PCA(50)),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "# model generation\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "# Predicting with a test dataset\n",
    "predicted = pipe.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\" test Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(\" Precision:\",metrics.precision_score(y_test, predicted, average=None))\n",
    "print(\" Recall:\",metrics.recall_score(y_test, predicted, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that we get the best results using "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec\n",
    "\n",
    "Next, we tried the word2vec technique. This technique is used to obtain numeric representations (vectors) of individual words. The obtained vectors are such that they retain the linguistic context of the words, meaning that words appearing in a similar context will have similar numerical representations. Training these representations requires large amount of data, so we used the pre-trained GloVe word embeddings downloaded from https://nlp.stanford.edu/projects/glove/. Next, we combined the vectors of the individual words into one vector representing the entire song by taking the average of the word vectors. This technique has been previously proposed for representing sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_embeddings_binary(embeddings_path):\n",
    "    \"\"\"\n",
    "    It loads embedding provided by glove which is saved as binary file. Loading of this model is\n",
    "    about  second faster than that of loading of txt glove file as model.\n",
    "    :param embeddings_path: path of glove file.\n",
    "    :return: glove model\n",
    "    \"\"\"\n",
    "    with codecs.open(embeddings_path + '.vocab', 'r', 'utf-8') as f_in:\n",
    "        index2word = [line.strip() for line in f_in]\n",
    "    wv = np.load(embeddings_path + '.npy')\n",
    "    model = {}\n",
    "    for i, w in enumerate(index2word):\n",
    "        model[w] = wv[i]\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model = load_embeddings_binary('../data/glove.6B.50d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w2v(sentence, model):\n",
    "    \"\"\"\n",
    "    :param sentence: inputs a single sentences whose word embedding is to be extracted.\n",
    "    :param model: inputs glove model.\n",
    "    :return: returns numpy array containing word embedding of all words    in input sentence.\n",
    "    \"\"\"\n",
    "    return np.mean(np.array([list(model[val]) for val in sentence.split() if val in model]), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['clean_lyrics'].apply(lambda lyrics: get_w2v(lyrics, w2v_model)).values # the features we want to analyze\n",
    "ylabels = df['class'] # the labels, or answers, we want to test against\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3, random_state=72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "\n",
    "We try to predict whether the song will be a hit or not based on the lyrics, using Logistic Regression. The test accuracy is 0.57. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test Accuracy: 0.5719579987646696\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(list(X_train), y_train)\n",
    "predicted = classifier.predict(list(X_test))\n",
    "\n",
    "print(\" test Accuracy:\",metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Networks\n",
    "\n",
    "We try to predict whether the song will be a hit or not based on the lyrics, using Neural Networks. We tried different parameters for density, optimizers, batch size, epochs, and for this values we got the best results. The test accuracy is 0.56."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim = 50))\n",
    "model.add(Activation('relu')) \n",
    "                           \n",
    "model.add(Dropout(0.1))   \n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3021 samples, validate on 756 samples\n",
      "Epoch 1/100\n",
      "3021/3021 [==============================] - 2s 727us/step - loss: 0.7007 - accuracy: 0.5204 - val_loss: 0.6934 - val_accuracy: 0.5146\n",
      "Epoch 2/100\n",
      "3021/3021 [==============================] - 1s 178us/step - loss: 0.6913 - accuracy: 0.5458 - val_loss: 0.6918 - val_accuracy: 0.5212\n",
      "Epoch 3/100\n",
      "3021/3021 [==============================] - 1s 185us/step - loss: 0.6852 - accuracy: 0.5392 - val_loss: 0.6863 - val_accuracy: 0.5450\n",
      "Epoch 4/100\n",
      "3021/3021 [==============================] - 1s 190us/step - loss: 0.6851 - accuracy: 0.5455 - val_loss: 0.6851 - val_accuracy: 0.5437\n",
      "Epoch 5/100\n",
      "3021/3021 [==============================] - 1s 195us/step - loss: 0.6834 - accuracy: 0.5511 - val_loss: 0.6878 - val_accuracy: 0.5569\n",
      "Epoch 6/100\n",
      "3021/3021 [==============================] - 1s 191us/step - loss: 0.6816 - accuracy: 0.5501 - val_loss: 0.6866 - val_accuracy: 0.5489\n",
      "Epoch 7/100\n",
      "3021/3021 [==============================] - 1s 193us/step - loss: 0.6816 - accuracy: 0.5574 - val_loss: 0.6858 - val_accuracy: 0.5529\n",
      "Epoch 8/100\n",
      "3021/3021 [==============================] - 1s 185us/step - loss: 0.6814 - accuracy: 0.5637 - val_loss: 0.6898 - val_accuracy: 0.5410\n",
      "Epoch 9/100\n",
      "3021/3021 [==============================] - 1s 184us/step - loss: 0.6811 - accuracy: 0.5674 - val_loss: 0.6835 - val_accuracy: 0.5503\n",
      "Epoch 10/100\n",
      "3021/3021 [==============================] - 1s 184us/step - loss: 0.6794 - accuracy: 0.5631 - val_loss: 0.6822 - val_accuracy: 0.5608\n",
      "Epoch 11/100\n",
      "3021/3021 [==============================] - 1s 193us/step - loss: 0.6784 - accuracy: 0.5740 - val_loss: 0.6880 - val_accuracy: 0.5556\n",
      "Epoch 12/100\n",
      "3021/3021 [==============================] - 1s 190us/step - loss: 0.6789 - accuracy: 0.5654 - val_loss: 0.6860 - val_accuracy: 0.5476\n",
      "Epoch 13/100\n",
      "3021/3021 [==============================] - 1s 197us/step - loss: 0.6784 - accuracy: 0.5664 - val_loss: 0.6822 - val_accuracy: 0.5463\n",
      "Epoch 14/100\n",
      "3021/3021 [==============================] - 1s 210us/step - loss: 0.6779 - accuracy: 0.5650 - val_loss: 0.6803 - val_accuracy: 0.5516\n",
      "Epoch 15/100\n",
      "3021/3021 [==============================] - 1s 194us/step - loss: 0.6762 - accuracy: 0.5753 - val_loss: 0.6806 - val_accuracy: 0.5556\n",
      "Epoch 16/100\n",
      "3021/3021 [==============================] - 1s 212us/step - loss: 0.6767 - accuracy: 0.5664 - val_loss: 0.6783 - val_accuracy: 0.5754\n",
      "Epoch 17/100\n",
      "3021/3021 [==============================] - 1s 194us/step - loss: 0.6750 - accuracy: 0.5750 - val_loss: 0.6863 - val_accuracy: 0.5582\n",
      "Epoch 18/100\n",
      "3021/3021 [==============================] - 1s 221us/step - loss: 0.6738 - accuracy: 0.5763 - val_loss: 0.6856 - val_accuracy: 0.5529\n",
      "Epoch 19/100\n",
      "3021/3021 [==============================] - 1s 246us/step - loss: 0.6731 - accuracy: 0.5756 - val_loss: 0.6839 - val_accuracy: 0.5529\n",
      "Epoch 20/100\n",
      "3021/3021 [==============================] - 1s 217us/step - loss: 0.6742 - accuracy: 0.5799 - val_loss: 0.6783 - val_accuracy: 0.5833\n",
      "Epoch 21/100\n",
      "3021/3021 [==============================] - 1s 227us/step - loss: 0.6733 - accuracy: 0.5746 - val_loss: 0.6780 - val_accuracy: 0.5807\n",
      "Epoch 22/100\n",
      "3021/3021 [==============================] - 1s 245us/step - loss: 0.6738 - accuracy: 0.5763 - val_loss: 0.6779 - val_accuracy: 0.5728\n",
      "Epoch 23/100\n",
      "3021/3021 [==============================] - 1s 204us/step - loss: 0.6723 - accuracy: 0.5799 - val_loss: 0.6766 - val_accuracy: 0.5608\n",
      "Epoch 24/100\n",
      "3021/3021 [==============================] - 1s 248us/step - loss: 0.6704 - accuracy: 0.5885 - val_loss: 0.6785 - val_accuracy: 0.5688\n",
      "Epoch 25/100\n",
      "3021/3021 [==============================] - 1s 226us/step - loss: 0.6717 - accuracy: 0.5674 - val_loss: 0.6834 - val_accuracy: 0.5622\n",
      "Epoch 26/100\n",
      "3021/3021 [==============================] - 1s 204us/step - loss: 0.6684 - accuracy: 0.5796 - val_loss: 0.6757 - val_accuracy: 0.5608\n",
      "Epoch 27/100\n",
      "3021/3021 [==============================] - 1s 213us/step - loss: 0.6684 - accuracy: 0.5879 - val_loss: 0.6777 - val_accuracy: 0.5807\n",
      "Epoch 28/100\n",
      "3021/3021 [==============================] - 1s 186us/step - loss: 0.6672 - accuracy: 0.5885 - val_loss: 0.6745 - val_accuracy: 0.5661\n",
      "Epoch 29/100\n",
      "3021/3021 [==============================] - 1s 195us/step - loss: 0.6663 - accuracy: 0.5899 - val_loss: 0.6735 - val_accuracy: 0.5741\n",
      "Epoch 30/100\n",
      "3021/3021 [==============================] - 1s 187us/step - loss: 0.6667 - accuracy: 0.5915 - val_loss: 0.6738 - val_accuracy: 0.5728\n",
      "Epoch 31/100\n",
      "3021/3021 [==============================] - 0s 165us/step - loss: 0.6671 - accuracy: 0.5909 - val_loss: 0.6813 - val_accuracy: 0.5529\n",
      "Epoch 32/100\n",
      "3021/3021 [==============================] - 1s 179us/step - loss: 0.6639 - accuracy: 0.5932 - val_loss: 0.6749 - val_accuracy: 0.5728\n",
      "Epoch 33/100\n",
      "3021/3021 [==============================] - 1s 207us/step - loss: 0.6635 - accuracy: 0.5905 - val_loss: 0.6743 - val_accuracy: 0.5701\n",
      "Epoch 34/100\n",
      "3021/3021 [==============================] - 1s 176us/step - loss: 0.6652 - accuracy: 0.5929 - val_loss: 0.6704 - val_accuracy: 0.5807\n",
      "Epoch 35/100\n",
      "3021/3021 [==============================] - 0s 161us/step - loss: 0.6632 - accuracy: 0.5852 - val_loss: 0.6724 - val_accuracy: 0.5807\n",
      "Epoch 36/100\n",
      "3021/3021 [==============================] - 1s 167us/step - loss: 0.6657 - accuracy: 0.5852 - val_loss: 0.6725 - val_accuracy: 0.5913\n",
      "Epoch 37/100\n",
      "3021/3021 [==============================] - 1s 180us/step - loss: 0.6626 - accuracy: 0.5885 - val_loss: 0.6738 - val_accuracy: 0.5741\n",
      "Epoch 38/100\n",
      "3021/3021 [==============================] - 1s 219us/step - loss: 0.6626 - accuracy: 0.5889 - val_loss: 0.6736 - val_accuracy: 0.5754\n",
      "Epoch 39/100\n",
      "3021/3021 [==============================] - 1s 214us/step - loss: 0.6589 - accuracy: 0.6021 - val_loss: 0.6808 - val_accuracy: 0.5714\n",
      "Epoch 40/100\n",
      "3021/3021 [==============================] - 1s 173us/step - loss: 0.6609 - accuracy: 0.5945 - val_loss: 0.6731 - val_accuracy: 0.5847\n",
      "Epoch 41/100\n",
      "3021/3021 [==============================] - 1s 196us/step - loss: 0.6603 - accuracy: 0.5929 - val_loss: 0.6708 - val_accuracy: 0.5913\n",
      "Epoch 42/100\n",
      "3021/3021 [==============================] - 1s 173us/step - loss: 0.6569 - accuracy: 0.5919 - val_loss: 0.6737 - val_accuracy: 0.5714\n",
      "Epoch 43/100\n",
      "3021/3021 [==============================] - 1s 197us/step - loss: 0.6594 - accuracy: 0.5932 - val_loss: 0.6727 - val_accuracy: 0.5820\n",
      "Epoch 44/100\n",
      "3021/3021 [==============================] - 1s 185us/step - loss: 0.6598 - accuracy: 0.5895 - val_loss: 0.6704 - val_accuracy: 0.5966\n",
      "Epoch 45/100\n",
      "3021/3021 [==============================] - 1s 172us/step - loss: 0.6593 - accuracy: 0.5925 - val_loss: 0.6714 - val_accuracy: 0.5886\n",
      "Epoch 46/100\n",
      "3021/3021 [==============================] - 1s 189us/step - loss: 0.6573 - accuracy: 0.5988 - val_loss: 0.6733 - val_accuracy: 0.5952\n",
      "Epoch 47/100\n",
      "3021/3021 [==============================] - 1s 222us/step - loss: 0.6562 - accuracy: 0.6051 - val_loss: 0.6715 - val_accuracy: 0.5913\n",
      "Epoch 48/100\n",
      "3021/3021 [==============================] - 1s 202us/step - loss: 0.6550 - accuracy: 0.6034 - val_loss: 0.6724 - val_accuracy: 0.5899\n",
      "Epoch 49/100\n",
      "3021/3021 [==============================] - 1s 186us/step - loss: 0.6560 - accuracy: 0.6001 - val_loss: 0.6735 - val_accuracy: 0.5767\n",
      "Epoch 50/100\n",
      "3021/3021 [==============================] - 1s 172us/step - loss: 0.6581 - accuracy: 0.6011 - val_loss: 0.6710 - val_accuracy: 0.5754\n",
      "Epoch 51/100\n",
      "3021/3021 [==============================] - 1s 166us/step - loss: 0.6519 - accuracy: 0.6081 - val_loss: 0.6669 - val_accuracy: 0.5966\n",
      "Epoch 52/100\n",
      "3021/3021 [==============================] - 1s 185us/step - loss: 0.6546 - accuracy: 0.5988 - val_loss: 0.6740 - val_accuracy: 0.5886\n",
      "Epoch 53/100\n",
      "3021/3021 [==============================] - 1s 180us/step - loss: 0.6514 - accuracy: 0.6001 - val_loss: 0.6716 - val_accuracy: 0.5847\n",
      "Epoch 54/100\n",
      "3021/3021 [==============================] - 1s 170us/step - loss: 0.6551 - accuracy: 0.6001 - val_loss: 0.6766 - val_accuracy: 0.5741\n",
      "Epoch 55/100\n",
      "3021/3021 [==============================] - 1s 171us/step - loss: 0.6527 - accuracy: 0.6097 - val_loss: 0.6776 - val_accuracy: 0.5714\n",
      "Epoch 56/100\n",
      "3021/3021 [==============================] - 1s 191us/step - loss: 0.6554 - accuracy: 0.6068 - val_loss: 0.6719 - val_accuracy: 0.5899\n",
      "Epoch 57/100\n",
      "3021/3021 [==============================] - 1s 186us/step - loss: 0.6509 - accuracy: 0.6101 - val_loss: 0.6738 - val_accuracy: 0.5847\n",
      "Epoch 58/100\n",
      "3021/3021 [==============================] - 1s 229us/step - loss: 0.6499 - accuracy: 0.6144 - val_loss: 0.6723 - val_accuracy: 0.5860\n",
      "Epoch 59/100\n",
      "3021/3021 [==============================] - 1s 296us/step - loss: 0.6493 - accuracy: 0.6154 - val_loss: 0.6771 - val_accuracy: 0.5780\n",
      "Epoch 60/100\n",
      "3021/3021 [==============================] - 1s 380us/step - loss: 0.6492 - accuracy: 0.6137 - val_loss: 0.6789 - val_accuracy: 0.5701\n",
      "Epoch 61/100\n",
      "3021/3021 [==============================] - 1s 328us/step - loss: 0.6510 - accuracy: 0.6157 - val_loss: 0.6726 - val_accuracy: 0.5688\n",
      "Epoch 62/100\n",
      "3021/3021 [==============================] - 1s 251us/step - loss: 0.6470 - accuracy: 0.6127 - val_loss: 0.6790 - val_accuracy: 0.5807\n",
      "Epoch 63/100\n",
      "3021/3021 [==============================] - 1s 231us/step - loss: 0.6501 - accuracy: 0.6041 - val_loss: 0.6731 - val_accuracy: 0.5939\n",
      "Epoch 64/100\n",
      "3021/3021 [==============================] - 1s 256us/step - loss: 0.6489 - accuracy: 0.6144 - val_loss: 0.6786 - val_accuracy: 0.5754\n",
      "Epoch 65/100\n",
      "3021/3021 [==============================] - 1s 212us/step - loss: 0.6477 - accuracy: 0.6111 - val_loss: 0.6735 - val_accuracy: 0.5926\n",
      "Epoch 66/100\n",
      "3021/3021 [==============================] - 1s 237us/step - loss: 0.6474 - accuracy: 0.6097 - val_loss: 0.6743 - val_accuracy: 0.5767\n",
      "Epoch 67/100\n",
      "3021/3021 [==============================] - 1s 238us/step - loss: 0.6477 - accuracy: 0.6144 - val_loss: 0.6755 - val_accuracy: 0.5992\n",
      "Epoch 68/100\n",
      "3021/3021 [==============================] - 1s 224us/step - loss: 0.6475 - accuracy: 0.6071 - val_loss: 0.6748 - val_accuracy: 0.5873\n",
      "Epoch 69/100\n",
      "3021/3021 [==============================] - 1s 215us/step - loss: 0.6474 - accuracy: 0.6091 - val_loss: 0.6760 - val_accuracy: 0.5873\n",
      "Epoch 70/100\n",
      "3021/3021 [==============================] - 1s 225us/step - loss: 0.6461 - accuracy: 0.6117 - val_loss: 0.6740 - val_accuracy: 0.5886\n",
      "Epoch 71/100\n",
      "3021/3021 [==============================] - 1s 182us/step - loss: 0.6468 - accuracy: 0.6137 - val_loss: 0.6765 - val_accuracy: 0.5807\n",
      "Epoch 72/100\n",
      "3021/3021 [==============================] - 1s 223us/step - loss: 0.6439 - accuracy: 0.6144 - val_loss: 0.6758 - val_accuracy: 0.5926\n",
      "Epoch 73/100\n",
      "3021/3021 [==============================] - 1s 223us/step - loss: 0.6431 - accuracy: 0.6230 - val_loss: 0.6733 - val_accuracy: 0.5754\n",
      "Epoch 74/100\n",
      "3021/3021 [==============================] - 1s 204us/step - loss: 0.6435 - accuracy: 0.6137 - val_loss: 0.6736 - val_accuracy: 0.5939\n",
      "Epoch 75/100\n",
      "3021/3021 [==============================] - 1s 220us/step - loss: 0.6445 - accuracy: 0.6114 - val_loss: 0.6774 - val_accuracy: 0.5820\n",
      "Epoch 76/100\n",
      "3021/3021 [==============================] - 1s 169us/step - loss: 0.6396 - accuracy: 0.6180 - val_loss: 0.6764 - val_accuracy: 0.5754\n",
      "Epoch 77/100\n",
      "3021/3021 [==============================] - 1s 221us/step - loss: 0.6413 - accuracy: 0.6097 - val_loss: 0.6787 - val_accuracy: 0.5648\n",
      "Epoch 78/100\n",
      "3021/3021 [==============================] - 1s 192us/step - loss: 0.6466 - accuracy: 0.6170 - val_loss: 0.6757 - val_accuracy: 0.6005\n",
      "Epoch 79/100\n",
      "3021/3021 [==============================] - 1s 189us/step - loss: 0.6408 - accuracy: 0.6137 - val_loss: 0.6784 - val_accuracy: 0.5847\n",
      "Epoch 80/100\n",
      "3021/3021 [==============================] - 1s 223us/step - loss: 0.6400 - accuracy: 0.6180 - val_loss: 0.6815 - val_accuracy: 0.5820\n",
      "Epoch 81/100\n",
      "3021/3021 [==============================] - 1s 180us/step - loss: 0.6404 - accuracy: 0.6316 - val_loss: 0.6775 - val_accuracy: 0.5807\n",
      "Epoch 82/100\n",
      "3021/3021 [==============================] - 1s 219us/step - loss: 0.6406 - accuracy: 0.6216 - val_loss: 0.6820 - val_accuracy: 0.5595\n",
      "Epoch 83/100\n",
      "3021/3021 [==============================] - 1s 228us/step - loss: 0.6427 - accuracy: 0.6193 - val_loss: 0.6889 - val_accuracy: 0.5675\n",
      "Epoch 84/100\n",
      "3021/3021 [==============================] - 1s 208us/step - loss: 0.6400 - accuracy: 0.6160 - val_loss: 0.6821 - val_accuracy: 0.5728\n",
      "Epoch 85/100\n",
      "3021/3021 [==============================] - 1s 224us/step - loss: 0.6383 - accuracy: 0.6289 - val_loss: 0.6833 - val_accuracy: 0.5754\n",
      "Epoch 86/100\n",
      "3021/3021 [==============================] - 1s 210us/step - loss: 0.6400 - accuracy: 0.6197 - val_loss: 0.6783 - val_accuracy: 0.5833\n",
      "Epoch 87/100\n",
      "3021/3021 [==============================] - 1s 220us/step - loss: 0.6401 - accuracy: 0.6197 - val_loss: 0.6769 - val_accuracy: 0.5767\n",
      "Epoch 88/100\n",
      "3021/3021 [==============================] - 1s 185us/step - loss: 0.6375 - accuracy: 0.6256 - val_loss: 0.6795 - val_accuracy: 0.5741\n",
      "Epoch 89/100\n",
      "3021/3021 [==============================] - 1s 222us/step - loss: 0.6406 - accuracy: 0.6226 - val_loss: 0.6787 - val_accuracy: 0.5754\n",
      "Epoch 90/100\n",
      "3021/3021 [==============================] - 1s 181us/step - loss: 0.6333 - accuracy: 0.6289 - val_loss: 0.6785 - val_accuracy: 0.5873\n",
      "Epoch 91/100\n",
      "3021/3021 [==============================] - 1s 195us/step - loss: 0.6358 - accuracy: 0.6346 - val_loss: 0.6808 - val_accuracy: 0.5741\n",
      "Epoch 92/100\n",
      "3021/3021 [==============================] - 1s 210us/step - loss: 0.6372 - accuracy: 0.6250 - val_loss: 0.6782 - val_accuracy: 0.5688\n",
      "Epoch 93/100\n",
      "3021/3021 [==============================] - 1s 173us/step - loss: 0.6336 - accuracy: 0.6197 - val_loss: 0.6829 - val_accuracy: 0.5807\n",
      "Epoch 94/100\n",
      "3021/3021 [==============================] - 1s 189us/step - loss: 0.6327 - accuracy: 0.6309 - val_loss: 0.6796 - val_accuracy: 0.5701\n",
      "Epoch 95/100\n",
      "3021/3021 [==============================] - 1s 174us/step - loss: 0.6364 - accuracy: 0.6250 - val_loss: 0.6837 - val_accuracy: 0.5913\n",
      "Epoch 96/100\n",
      "3021/3021 [==============================] - 1s 170us/step - loss: 0.6358 - accuracy: 0.6273 - val_loss: 0.6825 - val_accuracy: 0.5780\n",
      "Epoch 97/100\n",
      "3021/3021 [==============================] - 1s 173us/step - loss: 0.6340 - accuracy: 0.6296 - val_loss: 0.6865 - val_accuracy: 0.5913\n",
      "Epoch 98/100\n",
      "3021/3021 [==============================] - 1s 175us/step - loss: 0.6349 - accuracy: 0.6243 - val_loss: 0.6827 - val_accuracy: 0.6032\n",
      "Epoch 99/100\n",
      "3021/3021 [==============================] - 1s 176us/step - loss: 0.6325 - accuracy: 0.6293 - val_loss: 0.6827 - val_accuracy: 0.5939\n",
      "Epoch 100/100\n",
      "3021/3021 [==============================] - 1s 177us/step - loss: 0.6362 - accuracy: 0.6269 - val_loss: 0.6860 - val_accuracy: 0.5648\n"
     ]
    }
   ],
   "source": [
    "model_hist = model.fit(np.stack(X_train), y_train,\n",
    "                       batch_size=8, epochs=100,\n",
    "                       verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.7129344347820671\n",
      "Test accuracy: 0.5602223873138428\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(np.stack(X_test), y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If we compare the results, we can see that we got higher results using Logistic Regression**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Doc2Vec\n",
    "\n",
    "In our opinion, the low performance of the word2vec model is based on the fact that our documents (songs) are large and combining so many word vectors into one paragraph vector leads to bad performance. Doc2vec is an extension of the word2vec approach that tries to learn document representations based on the context instead of simply combining the representations of individual words. However, we could not find any pre-trained doc2vec models. We tried training our own model from our data, but this led to an expected bad performance. This is because we have only a few thousand paragraphs (songs) to train on, and getting good document representations requires having much larger datasets. We believe that having a larger corpus of songs would certainly improve the performance of the doc2vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.3, random_state=42)\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(lemmatizer.lemmatize(word.lower()))\n",
    "    return tokens\n",
    "\n",
    "train_tagged = train.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['clean_lyrics']), tags=[r['class']]), axis=1)\n",
    "test_tagged = test.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['clean_lyrics']), tags=[r['class']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3777/3777 [00:00<00:00, 1997212.08it/s]\n"
     ]
    }
   ],
   "source": [
    "cores = multiprocessing.cpu_count()\n",
    "\n",
    "model_dbow = Doc2Vec(dm=0, vector_size=100, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3777/3777 [00:00<00:00, 1790245.93it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2247713.71it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2213790.69it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2442850.61it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 1385628.11it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2236922.65it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 1626978.15it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2516982.24it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2491646.15it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 1845728.32it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2381164.32it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 1430160.35it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2248990.09it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 1870794.31it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2195383.34it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2361640.76it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2029970.04it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 1942836.18it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2006572.03it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2615899.31it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2624132.22it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 831726.06it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2382596.81it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2366933.54it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 1501742.93it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2455345.04it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2167152.70it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 1269585.37it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2204241.85it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2323197.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 60 s, sys: 751 ms, total: 1min\n",
      "Wall time: 19.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "\n",
    "We try to predict whether the song will be a hit or not using Logistic Regression. The test accuracy is 0.48, so it is worse than the base rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.4898085237801112\n",
      "Testing F1 score: 0.4893726416195995\n"
     ]
    }
   ],
   "source": [
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)\n",
    "\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Features\n",
    "\n",
    "We will try to predict whether a song will be a hit or not based on the Aaudio Features. The audio features are already normalized from Spotify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features = ['acousticness', 'danceability',  'energy',\n",
    "            'instrumentalness', 'liveness', 'loudness', 'mode',\n",
    "            'speechiness', 'tempo', 'time_signature', 'valence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[audio_features]\n",
    "y = df['class']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3, random_state=72)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression\n",
    "\n",
    "We try to predict whether the song will be a hit or not based on the Audio Features, using Logistic Regression. The test accuracy is 0.59."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test Accuracy: 0.5941939468807906\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "predicted = classifier.predict(X_test)\n",
    "\n",
    "print(\" test Accuracy:\",metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression - Polynomial Features\n",
    "\n",
    "We will generate a new feature matrix consisting of all polynomial combinations of the features with degree equal to the specified degree - 2, and try to predict whether the song will be a hit or not using Logistic Regression. The test accuracy is 0.61, so we can see an improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test Accuracy: 0.6145768993205682\n"
     ]
    }
   ],
   "source": [
    "poly = PolynomialFeatures(2)\n",
    "\n",
    "X_train = poly.fit_transform(X_train)\n",
    "X_test = poly.transform(X_test)\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "predicted = classifier.predict(X_test)\n",
    "\n",
    "print(\" test Accuracy:\", metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Neural Networks\n",
    "\n",
    "We try to predict whether the song will be a hit or not based on the Audio Features using Neural Networks. We tried different parameters for density, optimizers, batch size, epochs, and for this values we got the best results. The test accuracy is 0.53."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(30, input_dim = 78))\n",
    "model.add(Activation('relu')) \n",
    "\n",
    "model.add(Dropout(0.1))   \n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3021 samples, validate on 756 samples\n",
      "Epoch 1/100\n",
      "3021/3021 [==============================] - 1s 231us/step - loss: 145.5003 - accuracy: 0.4919 - val_loss: 5.4925 - val_accuracy: 0.5159\n",
      "Epoch 2/100\n",
      "3021/3021 [==============================] - 0s 139us/step - loss: 59.4291 - accuracy: 0.5002 - val_loss: 4.2968 - val_accuracy: 0.5132\n",
      "Epoch 3/100\n",
      "3021/3021 [==============================] - 0s 138us/step - loss: 23.8573 - accuracy: 0.5028 - val_loss: 4.2437 - val_accuracy: 0.4881\n",
      "Epoch 4/100\n",
      "3021/3021 [==============================] - 0s 135us/step - loss: 8.6086 - accuracy: 0.5220 - val_loss: 1.6504 - val_accuracy: 0.4907\n",
      "Epoch 5/100\n",
      "3021/3021 [==============================] - 0s 141us/step - loss: 1.7199 - accuracy: 0.5207 - val_loss: 0.7594 - val_accuracy: 0.5278\n",
      "Epoch 6/100\n",
      "3021/3021 [==============================] - 0s 140us/step - loss: 0.8257 - accuracy: 0.5151 - val_loss: 0.7245 - val_accuracy: 0.5093\n",
      "Epoch 7/100\n",
      "3021/3021 [==============================] - 0s 138us/step - loss: 0.7390 - accuracy: 0.5058 - val_loss: 0.6972 - val_accuracy: 0.5146\n",
      "Epoch 8/100\n",
      "3021/3021 [==============================] - 0s 150us/step - loss: 0.7150 - accuracy: 0.5108 - val_loss: 0.6931 - val_accuracy: 0.5185\n",
      "Epoch 9/100\n",
      "3021/3021 [==============================] - 0s 148us/step - loss: 0.7058 - accuracy: 0.4916 - val_loss: 0.6909 - val_accuracy: 0.5251\n",
      "Epoch 10/100\n",
      "3021/3021 [==============================] - 0s 131us/step - loss: 0.7134 - accuracy: 0.5088 - val_loss: 0.7096 - val_accuracy: 0.4907\n",
      "Epoch 11/100\n",
      "3021/3021 [==============================] - 0s 137us/step - loss: 0.7086 - accuracy: 0.4916 - val_loss: 0.7064 - val_accuracy: 0.4907\n",
      "Epoch 12/100\n",
      "3021/3021 [==============================] - 0s 141us/step - loss: 0.7109 - accuracy: 0.5031 - val_loss: 0.6925 - val_accuracy: 0.5172\n",
      "Epoch 13/100\n",
      "3021/3021 [==============================] - 0s 139us/step - loss: 0.6990 - accuracy: 0.5015 - val_loss: 0.6929 - val_accuracy: 0.5066\n",
      "Epoch 14/100\n",
      "3021/3021 [==============================] - 0s 137us/step - loss: 0.6974 - accuracy: 0.5118 - val_loss: 0.6918 - val_accuracy: 0.5146\n",
      "Epoch 15/100\n",
      "3021/3021 [==============================] - 0s 138us/step - loss: 0.6930 - accuracy: 0.5194 - val_loss: 0.6952 - val_accuracy: 0.4894\n",
      "Epoch 16/100\n",
      "3021/3021 [==============================] - 0s 138us/step - loss: 0.6921 - accuracy: 0.5227 - val_loss: 0.7001 - val_accuracy: 0.5119\n",
      "Epoch 17/100\n",
      "3021/3021 [==============================] - 0s 137us/step - loss: 0.6916 - accuracy: 0.5250 - val_loss: 0.6924 - val_accuracy: 0.5225\n",
      "Epoch 18/100\n",
      "3021/3021 [==============================] - 0s 144us/step - loss: 0.6910 - accuracy: 0.5273 - val_loss: 0.6949 - val_accuracy: 0.5132\n",
      "Epoch 19/100\n",
      "3021/3021 [==============================] - 0s 150us/step - loss: 0.6911 - accuracy: 0.5286 - val_loss: 0.6918 - val_accuracy: 0.5212\n",
      "Epoch 20/100\n",
      "3021/3021 [==============================] - 1s 180us/step - loss: 0.6914 - accuracy: 0.5190 - val_loss: 0.6915 - val_accuracy: 0.5198\n",
      "Epoch 21/100\n",
      "3021/3021 [==============================] - 0s 151us/step - loss: 0.6915 - accuracy: 0.5210 - val_loss: 0.6917 - val_accuracy: 0.5185\n",
      "Epoch 22/100\n",
      "3021/3021 [==============================] - 0s 141us/step - loss: 0.6927 - accuracy: 0.5074 - val_loss: 0.6919 - val_accuracy: 0.5172\n",
      "Epoch 23/100\n",
      "3021/3021 [==============================] - 0s 139us/step - loss: 0.6914 - accuracy: 0.5210 - val_loss: 0.6925 - val_accuracy: 0.5172\n",
      "Epoch 24/100\n",
      "3021/3021 [==============================] - 0s 143us/step - loss: 0.6912 - accuracy: 0.5263 - val_loss: 0.6914 - val_accuracy: 0.5225\n",
      "Epoch 25/100\n",
      "3021/3021 [==============================] - 0s 141us/step - loss: 0.6932 - accuracy: 0.5137 - val_loss: 0.6918 - val_accuracy: 0.5159\n",
      "Epoch 26/100\n",
      "3021/3021 [==============================] - 0s 144us/step - loss: 0.6922 - accuracy: 0.5210 - val_loss: 0.6922 - val_accuracy: 0.5106\n",
      "Epoch 27/100\n",
      "3021/3021 [==============================] - 0s 149us/step - loss: 0.6930 - accuracy: 0.5058 - val_loss: 0.6919 - val_accuracy: 0.5159\n",
      "Epoch 28/100\n",
      "3021/3021 [==============================] - 0s 137us/step - loss: 0.6936 - accuracy: 0.5058 - val_loss: 0.6921 - val_accuracy: 0.5106\n",
      "Epoch 29/100\n",
      "3021/3021 [==============================] - 0s 134us/step - loss: 0.6928 - accuracy: 0.5035 - val_loss: 0.6921 - val_accuracy: 0.5106\n",
      "Epoch 30/100\n",
      "3021/3021 [==============================] - 0s 144us/step - loss: 0.6927 - accuracy: 0.5035 - val_loss: 0.6921 - val_accuracy: 0.5106\n",
      "Epoch 31/100\n",
      "3021/3021 [==============================] - 0s 144us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6921 - val_accuracy: 0.5106\n",
      "Epoch 32/100\n",
      "3021/3021 [==============================] - 0s 136us/step - loss: 0.6928 - accuracy: 0.5035 - val_loss: 0.6921 - val_accuracy: 0.5106\n",
      "Epoch 33/100\n",
      "3021/3021 [==============================] - 0s 144us/step - loss: 0.6927 - accuracy: 0.5035 - val_loss: 0.6921 - val_accuracy: 0.5106\n",
      "Epoch 34/100\n",
      "3021/3021 [==============================] - 0s 141us/step - loss: 0.6927 - accuracy: 0.5035 - val_loss: 0.6921 - val_accuracy: 0.5106\n",
      "Epoch 35/100\n",
      "3021/3021 [==============================] - 0s 142us/step - loss: 0.6927 - accuracy: 0.5035 - val_loss: 0.6921 - val_accuracy: 0.5106\n",
      "Epoch 36/100\n",
      "3021/3021 [==============================] - 0s 141us/step - loss: 0.6927 - accuracy: 0.5035 - val_loss: 0.6921 - val_accuracy: 0.5106\n",
      "Epoch 37/100\n",
      "3021/3021 [==============================] - 0s 144us/step - loss: 0.6927 - accuracy: 0.5035 - val_loss: 0.6922 - val_accuracy: 0.5106\n",
      "Epoch 38/100\n",
      "3021/3021 [==============================] - 0s 143us/step - loss: 0.6930 - accuracy: 0.4985 - val_loss: 0.6922 - val_accuracy: 0.5106\n",
      "Epoch 39/100\n",
      "3021/3021 [==============================] - 0s 145us/step - loss: 0.6927 - accuracy: 0.5035 - val_loss: 0.6921 - val_accuracy: 0.5106\n",
      "Epoch 40/100\n",
      "3021/3021 [==============================] - 0s 147us/step - loss: 0.6927 - accuracy: 0.5035 - val_loss: 0.6921 - val_accuracy: 0.5106\n",
      "Epoch 41/100\n",
      "3021/3021 [==============================] - 0s 139us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6921 - val_accuracy: 0.5106\n",
      "Epoch 42/100\n",
      "3021/3021 [==============================] - 0s 139us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6921 - val_accuracy: 0.5106\n",
      "Epoch 43/100\n",
      "3021/3021 [==============================] - 0s 139us/step - loss: 0.6927 - accuracy: 0.5035 - val_loss: 0.6921 - val_accuracy: 0.5106\n",
      "Epoch 44/100\n",
      "3021/3021 [==============================] - 0s 140us/step - loss: 0.6927 - accuracy: 0.5035 - val_loss: 0.6921 - val_accuracy: 0.5106\n",
      "Epoch 45/100\n",
      "3021/3021 [==============================] - 0s 142us/step - loss: 0.6927 - accuracy: 0.4945 - val_loss: 0.6921 - val_accuracy: 0.5106\n",
      "Epoch 46/100\n",
      "3021/3021 [==============================] - 0s 137us/step - loss: 0.6927 - accuracy: 0.5035 - val_loss: 0.6921 - val_accuracy: 0.5106\n",
      "Epoch 47/100\n",
      "3021/3021 [==============================] - 0s 143us/step - loss: 0.6927 - accuracy: 0.5035 - val_loss: 0.6921 - val_accuracy: 0.5106\n",
      "Epoch 48/100\n",
      "3021/3021 [==============================] - 0s 142us/step - loss: 0.6927 - accuracy: 0.5035 - val_loss: 0.6922 - val_accuracy: 0.5106\n",
      "Epoch 49/100\n",
      "3021/3021 [==============================] - 0s 139us/step - loss: 0.6928 - accuracy: 0.5035 - val_loss: 0.6921 - val_accuracy: 0.5106\n",
      "Epoch 50/100\n",
      "3021/3021 [==============================] - 0s 135us/step - loss: 0.6927 - accuracy: 0.5035 - val_loss: 0.6921 - val_accuracy: 0.5106\n",
      "Epoch 51/100\n",
      "3021/3021 [==============================] - 0s 135us/step - loss: 0.6928 - accuracy: 0.5035 - val_loss: 0.6921 - val_accuracy: 0.5106\n",
      "Epoch 52/100\n",
      "3021/3021 [==============================] - 0s 140us/step - loss: 0.6927 - accuracy: 0.5035 - val_loss: 0.6921 - val_accuracy: 0.5106\n",
      "Epoch 53/100\n",
      "3021/3021 [==============================] - 0s 144us/step - loss: 0.6927 - accuracy: 0.5035 - val_loss: 0.6921 - val_accuracy: 0.5106\n",
      "Epoch 54/100\n",
      "3021/3021 [==============================] - 0s 141us/step - loss: 0.6927 - accuracy: 0.5035 - val_loss: 0.6921 - val_accuracy: 0.5106\n",
      "Epoch 55/100\n",
      "3021/3021 [==============================] - 0s 141us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6921 - val_accuracy: 0.5106\n",
      "Epoch 56/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3021/3021 [==============================] - 0s 142us/step - loss: 0.7152 - accuracy: 0.5041 - val_loss: 0.6925 - val_accuracy: 0.5106\n",
      "Epoch 57/100\n",
      "3021/3021 [==============================] - 0s 151us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 58/100\n",
      "3021/3021 [==============================] - 0s 145us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6925 - val_accuracy: 0.5106\n",
      "Epoch 59/100\n",
      "3021/3021 [==============================] - 0s 141us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6925 - val_accuracy: 0.5106\n",
      "Epoch 60/100\n",
      "3021/3021 [==============================] - 0s 145us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 61/100\n",
      "3021/3021 [==============================] - 0s 148us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 62/100\n",
      "3021/3021 [==============================] - 0s 145us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 63/100\n",
      "3021/3021 [==============================] - 0s 136us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 64/100\n",
      "3021/3021 [==============================] - 0s 143us/step - loss: 0.6932 - accuracy: 0.4982 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 65/100\n",
      "3021/3021 [==============================] - 0s 141us/step - loss: 0.6930 - accuracy: 0.4876 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 66/100\n",
      "3021/3021 [==============================] - 1s 171us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 67/100\n",
      "3021/3021 [==============================] - 0s 145us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 68/100\n",
      "3021/3021 [==============================] - 0s 155us/step - loss: 0.6930 - accuracy: 0.4969 - val_loss: 0.6925 - val_accuracy: 0.5106\n",
      "Epoch 69/100\n",
      "3021/3021 [==============================] - 1s 179us/step - loss: 0.6929 - accuracy: 0.5031 - val_loss: 0.6925 - val_accuracy: 0.5106\n",
      "Epoch 70/100\n",
      "3021/3021 [==============================] - 0s 146us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6925 - val_accuracy: 0.5106\n",
      "Epoch 71/100\n",
      "3021/3021 [==============================] - 0s 147us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6925 - val_accuracy: 0.5106\n",
      "Epoch 72/100\n",
      "3021/3021 [==============================] - 0s 137us/step - loss: 0.6932 - accuracy: 0.5028 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 73/100\n",
      "3021/3021 [==============================] - 0s 142us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 74/100\n",
      "3021/3021 [==============================] - 0s 145us/step - loss: 0.6930 - accuracy: 0.4846 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 75/100\n",
      "3021/3021 [==============================] - 0s 138us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 76/100\n",
      "3021/3021 [==============================] - 0s 154us/step - loss: 0.6932 - accuracy: 0.5028 - val_loss: 0.6925 - val_accuracy: 0.5106\n",
      "Epoch 77/100\n",
      "3021/3021 [==============================] - 0s 163us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 78/100\n",
      "3021/3021 [==============================] - 0s 150us/step - loss: 0.6932 - accuracy: 0.5028 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 79/100\n",
      "3021/3021 [==============================] - 0s 137us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 80/100\n",
      "3021/3021 [==============================] - 0s 142us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 81/100\n",
      "3021/3021 [==============================] - 0s 156us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 82/100\n",
      "3021/3021 [==============================] - 0s 140us/step - loss: 0.6929 - accuracy: 0.5031 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 83/100\n",
      "3021/3021 [==============================] - 0s 143us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 84/100\n",
      "3021/3021 [==============================] - 0s 144us/step - loss: 0.6932 - accuracy: 0.4889 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 85/100\n",
      "3021/3021 [==============================] - 0s 139us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 86/100\n",
      "3021/3021 [==============================] - 0s 149us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 87/100\n",
      "3021/3021 [==============================] - 0s 151us/step - loss: 0.6932 - accuracy: 0.5028 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 88/100\n",
      "3021/3021 [==============================] - 0s 150us/step - loss: 0.6930 - accuracy: 0.4972 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 89/100\n",
      "3021/3021 [==============================] - 0s 145us/step - loss: 0.6930 - accuracy: 0.4926 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 90/100\n",
      "3021/3021 [==============================] - 0s 145us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 91/100\n",
      "3021/3021 [==============================] - 0s 146us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 92/100\n",
      "3021/3021 [==============================] - 0s 145us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 93/100\n",
      "3021/3021 [==============================] - 0s 144us/step - loss: 0.6954 - accuracy: 0.5048 - val_loss: 0.6925 - val_accuracy: 0.5106\n",
      "Epoch 94/100\n",
      "3021/3021 [==============================] - 0s 146us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6925 - val_accuracy: 0.5106\n",
      "Epoch 95/100\n",
      "3021/3021 [==============================] - 0s 141us/step - loss: 0.6932 - accuracy: 0.5028 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 96/100\n",
      "3021/3021 [==============================] - 0s 144us/step - loss: 0.6932 - accuracy: 0.5028 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 97/100\n",
      "3021/3021 [==============================] - 0s 143us/step - loss: 0.6930 - accuracy: 0.4965 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 98/100\n",
      "3021/3021 [==============================] - 0s 137us/step - loss: 0.6930 - accuracy: 0.4922 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 99/100\n",
      "3021/3021 [==============================] - 0s 161us/step - loss: 0.6929 - accuracy: 0.5031 - val_loss: 0.6926 - val_accuracy: 0.5106\n",
      "Epoch 100/100\n",
      "3021/3021 [==============================] - 0s 147us/step - loss: 0.6930 - accuracy: 0.5031 - val_loss: 0.6925 - val_accuracy: 0.5106\n"
     ]
    }
   ],
   "source": [
    "model_hist = model.fit(X_train, y_train,\n",
    "                       batch_size=10, epochs=100,\n",
    "                       verbose=1, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.692354913513332\n",
      "Test accuracy: 0.5355157256126404\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('Test loss:', score[0])\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**If we compare the results, we can see that we got the highest accuracy when we used Logistic Regression with polynomial features expansion of the matrix.**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
