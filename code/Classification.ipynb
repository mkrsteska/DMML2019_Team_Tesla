{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import multiprocessing\n",
        "from gensim.models import Doc2Vec\n",
        "from tqdm import tqdm\n",
        "from sklearn import utils\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "import spacy\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_lyrics(lyrics):\n",
        "    if lyrics is None:\n",
        "        return lyrics\n",
        "    \n",
        "    # combine lists of tokens into single string\n",
        "    lyrics = ' '.join(lyrics)\n",
        "            \n",
        "    # remove apostrophes\n",
        "    lyrics = lyrics.replace('\\'', '')\n",
        "            \n",
        "    # remove song structure tags or instructions in brackets\n",
        "    lyrics = re.sub(r'[\\*\\[|\\(|\\{].*\\n*.*[\\]\\)\\}\\*]' , ' ', lyrics)\n",
        "   \n",
        "    # remove variations of Verse 1, VERSE 2, etc...\n",
        "    for verse in ['verse', 'VERSE', 'Verse']:\n",
        "        lyrics = re.sub(verse+' \\d*', '', lyrics)\n",
        "    \n",
        "    # some structure markers formatted as allcaps without brackets\n",
        "    for word in ['OUTRO', 'INSTRUMENTAL', 'PRE', 'HOOK',\n",
        "                 'PRODUCED', 'REFRAIN', 'POST', 'REPEAT', '2x', '3x', '4x',\n",
        "                 'CHORUS', 'INTRO', 'INTERLUDE']:\n",
        "        lyrics = lyrics.replace(word, '')\n",
        "        \n",
        "    # remove varations of Chorus\n",
        "    lyrics = re.sub(r'\\n*Chorus:*.*' , ' ', lyrics)\n",
        "    lyrics = re.sub(r'^Chorus:*.*' , ' ', lyrics)\n",
        "    lyrics = re.sub(r'\\nRepeat [C|c]horus:*.*' , ' ', lyrics)\n",
        "    \n",
        "    # remove variations of Intro\n",
        "    lyrics = re.sub(r'Intro[\\s|\\n|:].*', ' ', lyrics)\n",
        "    \n",
        "    # remove variations of Instrumental\n",
        "    lyrics = re.sub(r'-+.*[i|I]nstrumental.*-+', ' ', lyrics)\n",
        "    lyrics = re.sub(r'\\nBrief instrumental.*\\n', ' ', lyrics)\n",
        "    lyrics = re.sub(r'\\nInstrumental', ' ', lyrics)\n",
        "    lyrics = re.sub(r'\\nInstrumental break', ' ', lyrics)\n",
        "    lyrics = re.sub(r'\\nInstrumental--', ' ', lyrics)\n",
        "    lyrics = re.sub(r'\\n~Instrumental~', ' ', lyrics)\n",
        "    \n",
        "    # remove variations of Bridge\n",
        "    lyrics = re.sub(r'\\n\\[*Bridge:\\[*', ' ', lyrics)\n",
        "    \n",
        "    # remove variations of Hook\n",
        "    lyrics = re.sub(r'Hook:.*', ' ', lyrics)\n",
        "    \n",
        "    # remove varations of Repeat\n",
        "    lyrics = re.sub(r'Repeat\\s.*', ' ', lyrics)\n",
        "    lyrics = re.sub(r'\\nRepeat$', ' ', lyrics)\n",
        "    \n",
        "    # remove credits\n",
        "    lyrics = re.sub(r'.*[P|p]roduced [B|b]y.*', ' ', lyrics)\n",
        "    lyrics = re.sub(r'.*[W|w]ritten [B|b]y.*', ' ', lyrics)\n",
        "    \n",
        "    # remove strays and typos\n",
        "    lyrics = re.sub(r'\\[Outro\\[', ' ', lyrics)\n",
        "    lyrics = re.sub(r'Sax & background & instrumental\\)', ' ', lyrics)\n",
        "    lyrics = re.sub(r'\\nSource: ', ' ', lyrics)\n",
        "    lyrics = re.sub(r'Shotgun 2: 58 Trk 1 \\n  \\nJr. Walker & The All Stars '\\\n",
        "                    +'\\nAnd/or The Funk Brothers - instrumental \\nPop Chart '\\\n",
        "                    +'#4 Feb 13, 1965 \\nSoul Label - 35008   \\n ', ' ', lyrics)\n",
        "    lyrics = re.sub(r'- musical interlude -', ' ', lyrics)\n",
        "    lyrics = re.sub(r'\\nRefrain:', ' ', lyrics)\n",
        "            \n",
        "    # replace all punctuations with spaces\n",
        "    lyrics = re.sub(r'[^\\w\\s]', ' ', lyrics)\n",
        "            \n",
        "    # replace consecutive whitespaces with single space\n",
        "    lyrics = re.sub(r'\\s+', ' ', lyrics)\n",
        "    \n",
        "    # convert all tokens to lowercase\n",
        "    lyrics = lyrics.lower()\n",
        "\n",
        "    if lyrics[:29] == 'we do not have the lyrics for' or lyrics == 'instrumental':\n",
        "        lyrics = None\n",
        "    return lyrics\n"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "with open('../data/top_hits_lyrics.json') as json_file:\n",
        "    top_hits_lyrics = json.load(json_file)"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "top_hits_lyrics[0]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 4,
          "data": {
            "text/plain": [
              "{'id': '1rfofaqEpACxVEHIZBJe6W',\n",
              " 'lyrics': ['[Intro: Pharrell Williams]',\n",
              "  '\\nHey',\n",
              "  '\\n',\n",
              "  '\\n[Chorus: Camila Cabello & ',\n",
              "  'Pharrell Williams',\n",
              "  ']',\n",
              "  '\\n',\n",
              "  'Havana, ooh na-na (',\n",
              "  'Ayy',\n",
              "  ')',\n",
              "  '\\nHalf of my heart is in Havana, ooh na-na (',\n",
              "  'Ayy, ayy',\n",
              "  ')',\n",
              "  '\\n',\n",
              "  'He took me back to East Atlanta, na-na-na, ah',\n",
              "  '\\n',\n",
              "  'Oh, but my heart is in Havana (',\n",
              "  'Ayy',\n",
              "  ')',\n",
              "  \"\\nThere's somethin' 'bout his manners (\",\n",
              "  'Uh-huh',\n",
              "  ')',\n",
              "  '\\n',\n",
              "  'Havana, ooh na-na (',\n",
              "  'Uh',\n",
              "  ')',\n",
              "  '\\n',\n",
              "  '\\n[Verse 1: Camila Cabello & ',\n",
              "  'Pharrell Williams',\n",
              "  ']',\n",
              "  '\\n',\n",
              "  'He didn\\'t walk up with that \"how you doin\\'?\" (',\n",
              "  'Uh',\n",
              "  ')',\n",
              "  '\\nWhen he came in the room',\n",
              "  \"\\nHe said there's a lot of girls I can do with (\",\n",
              "  'Uh',\n",
              "  ')',\n",
              "  \"\\nBut I can't without you\",\n",
              "  '\\nI knew him forever in a minute (',\n",
              "  'Hey',\n",
              "  ')',\n",
              "  '\\nThat summer night in June',\n",
              "  '\\n',\n",
              "  'And papa says he got malo in him (',\n",
              "  'Uh',\n",
              "  ')',\n",
              "  \"\\nHe got me feelin' like...\",\n",
              "  '\\n',\n",
              "  '\\n[Pre-Chorus: Camila Cabello & ',\n",
              "  'Pharrell Williams',\n",
              "  ']',\n",
              "  '\\nOoh, ooh-ooh-ooh-ooh-ooh-ooh-ooh (Ayy)',\n",
              "  '\\nI knew it when I met him (Ayy), I loved him when I left him',\n",
              "  \"\\nGot me feelin' like, ooh, ooh-ooh-ooh-ooh-ooh-ooh-ooh\",\n",
              "  '\\nAnd then I had to tell him, I had to go',\n",
              "  '\\nOh na-na-na-na-na (',\n",
              "  'Woo',\n",
              "  ')',\n",
              "  '\\n',\n",
              "  '\\n[Chorus: Camila Cabello & ',\n",
              "  'Pharrell Williams',\n",
              "  ']',\n",
              "  '\\n',\n",
              "  'Havana, ooh na-na (',\n",
              "  'Ayy, hey',\n",
              "  ')',\n",
              "  '\\nHalf of my heart is in Havana, ooh na-na (',\n",
              "  'Ayy, ayy, uh-huh',\n",
              "  ')',\n",
              "  '\\n',\n",
              "  'He took me back to East Atlanta, na-na-na',\n",
              "  '\\n',\n",
              "  'Oh, but my heart is in Havana (',\n",
              "  'Huh',\n",
              "  ')',\n",
              "  '\\nMy heart is in Havana (',\n",
              "  'Ayy',\n",
              "  ')',\n",
              "  '\\nHavana, ooh na-na',\n",
              "  '\\n',\n",
              "  '\\n',\n",
              "  '[Verse 2: Young Thug]',\n",
              "  '\\n',\n",
              "  '(Jeffery)',\n",
              "  '\\n',\n",
              "  'Just graduated, fresh on campus, mmm',\n",
              "  '\\nFresh out East Atlanta with no manners, damn (Fresh out East Atlanta)',\n",
              "  '\\nBump on her bumper like a traffic jam',\n",
              "  '\\n',\n",
              "  'Hey, I was quick to pay that girl like Uncle Sam (Here you go, ayy)',\n",
              "  '\\n',\n",
              "  'Back it on me (Back it up)',\n",
              "  \"\\nShawty cravin' on me, get to eatin' on me (On me)\",\n",
              "  '\\nShe waited on me (And what?)',\n",
              "  \"\\nShawty cakin' on me, got the bacon on me (Wait up)\",\n",
              "  \"\\nThis is history in the makin', homie (Homie)\",\n",
              "  '\\n',\n",
              "  'Point blank, close range, that B (Tah, tah)',\n",
              "  \"\\nIf it cost a million, that's me (That's me)\",\n",
              "  '\\n',\n",
              "  \"I was gettin' mula, baby\",\n",
              "  '\\n',\n",
              "  '\\n[Chorus: Camila Cabello & ',\n",
              "  'Pharrell ',\n",
              "  'Williams',\n",
              "  ']',\n",
              "  '\\n',\n",
              "  'Havana, ooh na-na (',\n",
              "  'Ayy, ayy',\n",
              "  ')',\n",
              "  '\\nHalf of my heart is in Havana, ooh na-na (Oh, ',\n",
              "  'ayy, ayy, uh-huh',\n",
              "  ')',\n",
              "  '\\n',\n",
              "  'He took me back to East Atlanta, na-na-na (Oh, no)',\n",
              "  '\\n',\n",
              "  'Oh, but my heart is in Havana (',\n",
              "  'Huh',\n",
              "  ')',\n",
              "  '\\nMy heart is in Havana (',\n",
              "  'Ayy',\n",
              "  ')',\n",
              "  '\\nHavana, ooh na-na',\n",
              "  '\\n',\n",
              "  '\\n[Bridge: Starrah & ',\n",
              "  'Camila Cabello',\n",
              "  ']',\n",
              "  '\\n',\n",
              "  'Ooh na-na, oh, na-na-na (',\n",
              "  'Ooh, ooh-ooh-ooh-ooh-ooh-ooh',\n",
              "  ')',\n",
              "  '\\n',\n",
              "  'Take me back, back, back like...',\n",
              "  '\\nOoh na-na, oh, na-na-na (Yeah, babe)',\n",
              "  '\\n',\n",
              "  'Take me back, back, back like...',\n",
              "  '\\nOoh na-na, oh, na-na-na (Yeah, yeah)',\n",
              "  '\\n',\n",
              "  'Take me back, back, back like...',\n",
              "  '\\nOoh na-na, oh, na-na-na (Yeah, babe)',\n",
              "  '\\n',\n",
              "  'Take me back, back, back',\n",
              "  '\\n',\n",
              "  'Hey, hey...',\n",
              "  '\\nOoh, ooh-ooh-ooh-ooh-ooh-ooh-ooh (Hey)',\n",
              "  '\\nOoh, ooh-ooh-ooh-ooh-ooh-ooh-ooh (Hey)',\n",
              "  '\\nTake me back to my Havana...',\n",
              "  '\\n',\n",
              "  '\\n[Chorus: Camila Cabello & ',\n",
              "  'Pharrell Williams',\n",
              "  ']',\n",
              "  '\\n',\n",
              "  'Havana, ooh na-na',\n",
              "  '\\nHalf of my heart is in Havana, ooh na-na (Oh, yeah)',\n",
              "  '\\n',\n",
              "  'He took me back to East Atlanta, na-na-na (',\n",
              "  'Ayy, ayy',\n",
              "  ')',\n",
              "  '\\n',\n",
              "  'Oh, but my heart is in Havana',\n",
              "  '\\nMy heart is in Havana (',\n",
              "  'Ayy',\n",
              "  ')',\n",
              "  '\\nHavana, ooh na-na (',\n",
              "  'Uh-huh',\n",
              "  ')',\n",
              "  '\\n',\n",
              "  '\\n[Outro: Starrah & ',\n",
              "  'Camila Cabello',\n",
              "  ']',\n",
              "  '\\n',\n",
              "  'Oh, na-na-na (',\n",
              "  'Oh, na, yeah',\n",
              "  ')',\n",
              "  '\\nOh, na-na-na',\n",
              "  '\\nOh, na-na-na (',\n",
              "  'No, no, no, take me back',\n",
              "  ')',\n",
              "  '\\nOh, na-na-na',\n",
              "  '\\n',\n",
              "  'Havana, ooh na-na'],\n",
              " 'source': 'genius.com'}"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 4,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "top_hits_df = pd.DataFrame(top_hits_lyrics)\n",
        "top_hits_df['clean_lyrics'] = top_hits_df['lyrics'].apply(lambda x: clean_lyrics(x))\n",
        "top_hits_df = top_hits_df[top_hits_df['source'].notnull()]\n",
        "top_hits_df = top_hits_df[top_hits_df['clean_lyrics'].notnull()]"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "top_hits_df.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 6,
          "data": {
            "text/plain": [
              "(2805, 4)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 6,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "with open('../data/songs_lyrics_5000.json') as json_file:\n",
        "    not_hits_1 = json.load(json_file)"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "with open('../data/songs_lyrics_10000.json') as json_file:\n",
        "    not_hits_2 = json.load(json_file)"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "not_hits_lyrics = not_hits_1 + not_hits_2"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "with open('../data/not_hits_lyrics.json', 'w') as f:\n",
        "        json.dump(not_hits_lyrics, f)"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "not_hits_df = pd.DataFrame(not_hits_lyrics)\n",
        "not_hits_df['clean_lyrics'] = not_hits_df['lyrics'].apply(lambda x: clean_lyrics(x))\n",
        "not_hits_df = not_hits_df[not_hits_df['source'].notnull()]\n",
        "not_hits_df = not_hits_df[not_hits_df['clean_lyrics'].notnull()]"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "not_hits_df.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 12,
          "data": {
            "text/plain": [
              "(7937, 4)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 12,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO: stratified sampling by decade\n",
        "not_hits_df = not_hits_df.sample(n=top_hits_df.shape[0])"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "not_hits_df.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 14,
          "data": {
            "text/plain": [
              "(2805, 4)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 14,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "print(not_hits_df['clean_lyrics'].iloc[0])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " its been the longest winter without you i didnt know where to turn to see somehow i cant forget you after all that weve been through going coming thought i heard a knock whos there no one thinking that i deserve it now i realize that i really didnt know if you didnt notice you mean everything quickly im learning to love again all i know is imma be okay thought i couldnt live without you its gonna hurt when it heals too itll all get better in time and even though i really love you im gonna smile cause i deserve to itll all get better in time i couldnt turn on the tv without something there to remind me was it all that easy to just put aside your feelings if im dreaming dont wanna laugh hurt my feelings but thats the path i believe in and i know that time will heal it if you didnt notice boy you meant everything quickly im learning to love again all i know is imma be okay thought i couldnt live without you its gonna hurt when it heals too itll all get better in time and even though i really love you im gonna smile cause i deserve to itll all get better in time its time i let you go so i can be free and live my life how it should be no matter how hard it is ill be fine without you yes i will thought i couldnt live without you its gonna hurt when it heals too itll all get better in time and even though i really loved you im gonna smile cause i deserve to yes i do itll all get better in time thought i couldnt live without you its gonna hurt when it heals too itll all get better in time and even though i really loved you gonna smile cause i deserve to\n"
          ]
        }
      ],
      "execution_count": 15,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "top_hits_df['class'] = 1\n",
        "not_hits_df['class'] = 0\n",
        "df = pd.concat([top_hits_df, not_hits_df])"
      ],
      "outputs": [],
      "execution_count": 16,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.shape"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 17,
          "data": {
            "text/plain": [
              "(5610, 5)"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 17,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.to_json(r'/Users/Samuel/Documents/GitHub/DMML2019_Team_Tesla/data/lyrics_df.json', orient='split', index=None)"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Doc2Vec"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df, test_size=0.3, random_state=42)\n",
        "lemmatizer = WordNetLemmatizer() \n",
        "\n",
        "def tokenize_text(text):\n",
        "    tokens = []\n",
        "    for sent in nltk.sent_tokenize(text):\n",
        "        for word in nltk.word_tokenize(sent):\n",
        "            if len(word) < 2:\n",
        "                continue\n",
        "            tokens.append(lemmatizer.lemmatize(word.lower()))\n",
        "    return tokens\n",
        "\n",
        "train_tagged = train.apply(\n",
        "    lambda r: TaggedDocument(words=tokenize_text(r['clean_lyrics']), tags=[r['class']]), axis=1)\n",
        "test_tagged = test.apply(\n",
        "    lambda r: TaggedDocument(words=tokenize_text(r['clean_lyrics']), tags=[r['class']]), axis=1)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "train_tagged.values[1]"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cores = multiprocessing.cpu_count()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model_dbow = Doc2Vec(dm=0, vector_size=100, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
        "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for epoch in range(30):\n",
        "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
        "    model_dbow.alpha -= 0.002\n",
        "    model_dbow.min_alpha = model_dbow.alpha"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vec_for_learning(model, tagged_docs):\n",
        "    sents = tagged_docs.values\n",
        "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
        "    return targets, regressors"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
        "y_test, X_test = vec_for_learning(model_dbow, test_tagged)\n",
        "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_test)\n",
        "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bag Of Words"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from spacy.lang.en import English\n",
        "\n",
        "# Create our list of punctuation marks\n",
        "punctuations = string.punctuation\n",
        "\n",
        "# Create our list of stopwords\n",
        "nlp = spacy.load('en')\n",
        "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
        "\n",
        "# Load English tokenizer, tagger, parser, NER and word vectors\n",
        "parser = English()\n",
        "\n",
        "# Creating our tokenizer function\n",
        "def spacy_tokenizer(sentence):\n",
        "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
        "    mytokens = parser(sentence)\n",
        "\n",
        "    # Lemmatizing each token and converting each token into lowercase\n",
        "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
        "\n",
        "    # Removing stop words\n",
        "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
        "\n",
        "    # return preprocessed list of tokens\n",
        "    return mytokens"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['clean_lyrics'] # the features we want to analyze\n",
        "ylabels = df['class'] # the labels, or answers, we want to test against\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3, random_state=72)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = LogisticRegression(solver=\"lbfgs\")\n",
        "\n",
        "# Create pipeline using Bag of Words\n",
        "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "# model generation\n",
        "pipe.fit(X_train,y_train)\n",
        "\n",
        "from sklearn import metrics\n",
        "# Predicting with a test dataset\n",
        "predicted = pipe.predict(X_test)\n",
        "\n",
        "# Model Accuracy\n",
        "print(\" test Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
        "print(\" Precision:\",metrics.precision_score(y_test, predicted, average=None))\n",
        "print(\" Recall:\",metrics.recall_score(y_test, predicted, average=None))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = RandomForestClassifier(n_estimators=1000)\n",
        "\n",
        "# Create pipeline using Bag of Words\n",
        "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "# model generation\n",
        "pipe.fit(X_train,y_train)\n",
        "\n",
        "from sklearn import metrics\n",
        "# Predicting with a test dataset\n",
        "predicted = pipe.predict(X_test)\n",
        "\n",
        "# Model Accuracy\n",
        "print(\" test Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
        "print(\" Precision:\",metrics.precision_score(y_test, predicted, average=None))\n",
        "print(\" Recall:\",metrics.recall_score(y_test, predicted, average=None))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Audio Features"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "with open('../data/top_hits.json') as json_file:\n",
        "    top_hits = json.load(json_file)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "top_hits_songs_df = pd.DataFrame(top_hits)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "top_hits_merged_df = pd.merge(top_hits_df, top_hits_songs_df, on='id', how='inner')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "top_hits_merged_df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "with open('../data/songs.json') as json_file:\n",
        "    not_hits = json.load(json_file)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "not_hits_songs_df = pd.DataFrame(not_hits)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "not_hits_merged_df = pd.merge(not_hits_df, not_hits_songs_df, on='id', how='inner')"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "not_hits_merged_df.shape"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "merged_df = pd.concat([top_hits_merged_df, not_hits_merged_df])"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "audio_features = ['acousticness', 'danceability',  'energy',\n",
        "            'instrumentalness', 'liveness', 'loudness', 'mode',\n",
        "            'speechiness', 'tempo', 'time_signature', 'valence']"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "X = merged_df[audio_features]\n",
        "y = merged_df['class']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3, random_state=72)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train, y_train)\n",
        "predicted = classifier.predict(X_test)\n",
        "print(\" test Accuracy:\",metrics.accuracy_score(y_test, predicted))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "0.15.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}