{
<<<<<<< HEAD
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import re\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from nltk.corpus import stopwords\n",
    "from gensim.models.doc2vec import TaggedDocument\n",
    "import multiprocessing\n",
    "from gensim.models import Doc2Vec\n",
    "from tqdm import tqdm\n",
    "from sklearn import utils\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.base import TransformerMixin\n",
    "from sklearn.pipeline import Pipeline\n",
    "import spacy\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/top_hits_merged_clean_lyrics_audio_features.json') as json_file:\n",
    "    top_hits = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/not_hits_merged_clean_lyrics_audio_features.json') as json_file:\n",
    "    not_hits = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_hits_df = pd.read_json(top_hits)\n",
    "not_hits_df = pd.read_json(not_hits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_hits_df['class'] = 1\n",
    "not_hits_df['class'] = 0\n",
    "df = pd.concat([top_hits_df, not_hits_df])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Doc2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.3, random_state=42)\n",
    "lemmatizer = WordNetLemmatizer() \n",
    "\n",
    "def tokenize_text(text):\n",
    "    tokens = []\n",
    "    for sent in nltk.sent_tokenize(text):\n",
    "        for word in nltk.word_tokenize(sent):\n",
    "            if len(word) < 2:\n",
    "                continue\n",
    "            tokens.append(lemmatizer.lemmatize(word.lower()))\n",
    "    return tokens\n",
    "\n",
    "train_tagged = train.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['clean_lyrics']), tags=[r['class']]), axis=1)\n",
    "test_tagged = test.apply(\n",
    "    lambda r: TaggedDocument(words=tokenize_text(r['clean_lyrics']), tags=[r['class']]), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
=======
  "cells": [
>>>>>>> ac750436c7ed48ab2858a2e41994044fd4bc96d7
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import pandas as pd\n",
        "import re\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from nltk.corpus import stopwords\n",
        "from gensim.models.doc2vec import TaggedDocument\n",
        "import multiprocessing\n",
        "from gensim.models import Doc2Vec\n",
        "from tqdm import tqdm\n",
        "from sklearn import utils\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, f1_score\n",
        "from nltk.stem import WordNetLemmatizer \n",
        "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
        "from sklearn.base import TransformerMixin\n",
        "from sklearn.pipeline import Pipeline\n",
        "import spacy\n",
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {}
    },
    {
<<<<<<< HEAD
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3777/3777 [00:00<00:00, 626285.28it/s]\n"
     ]
    }
   ],
   "source": [
    "model_dbow = Doc2Vec(dm=0, vector_size=100, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
    "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3777/3777 [00:00<00:00, 2615467.43it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2406849.93it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2189315.40it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2431975.16it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2823865.63it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 1572864.00it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2430109.86it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2629795.19it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2095487.59it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2401377.32it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2555967.44it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2408679.67it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 1182053.89it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 1224635.61it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2855937.66it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2363049.85it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2414185.65it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2358827.61it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2664293.01it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2578432.00it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2694198.33it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 1421434.38it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2669231.04it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2771013.85it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2649144.85it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2312346.55it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2804370.01it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2458393.27it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2582214.54it/s]\n",
      "100%|██████████| 3777/3777 [00:00<00:00, 2285326.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 54.9 s, sys: 674 ms, total: 55.6 s\n",
      "Wall time: 17.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for epoch in range(30):\n",
    "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
    "    model_dbow.alpha -= 0.002\n",
    "    model_dbow.min_alpha = model_dbow.alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vec_for_learning(model, tagged_docs):\n",
    "    sents = tagged_docs.values\n",
    "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
    "    return targets, regressors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
=======
      "cell_type": "code",
      "source": [
        "with open('../data/top_hits_merged_clean_lyrics_audio_features.json') as json_file:\n",
        "    top_hits = json.load(json_file)"
      ],
      "outputs": [],
      "execution_count": 2,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "with open('../data/not_hits_merged_clean_lyrics_audio_features.json') as json_file:\n",
        "    not_hits = json.load(json_file)"
      ],
      "outputs": [],
      "execution_count": 3,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "top_hits_df = pd.read_json(top_hits)\n",
        "not_hits_df = pd.read_json(not_hits)"
      ],
      "outputs": [],
      "execution_count": 4,
      "metadata": {}
    },
>>>>>>> ac750436c7ed48ab2858a2e41994044fd4bc96d7
    {
      "cell_type": "code",
      "source": [
        "top_hits_df['class'] = 1\n",
        "not_hits_df['class'] = 0\n",
        "df = pd.concat([top_hits_df, not_hits_df])"
      ],
      "outputs": [],
      "execution_count": 5,
      "metadata": {}
    },
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing accuracy 0.49351451513279804\n",
      "Testing F1 score: 0.4930355894001325\n"
     ]
    }
   ],
   "source": [
    "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
    "y_test, X_test = vec_for_learning(model_dbow, test_tagged)\n",
    "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred = logreg.predict(X_test)\n",
    "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
    "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from spacy.lang.en import English\n",
    "\n",
    "# Create our list of punctuation marks\n",
    "punctuations = string.punctuation\n",
    "\n",
    "# Create our list of stopwords\n",
    "nlp = spacy.load('en')\n",
    "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
    "\n",
    "# Load English tokenizer, tagger, parser, NER and word vectors\n",
    "parser = English()\n",
    "\n",
    "# Creating our tokenizer function\n",
    "def spacy_tokenizer(sentence):\n",
    "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
    "    mytokens = parser(sentence)\n",
    "\n",
    "    # Lemmatizing each token and converting each token into lowercase\n",
    "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
    "\n",
    "    # Removing stop words\n",
    "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
    "\n",
    "    # return preprocessed list of tokens\n",
    "    return mytokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['clean_lyrics'] # the features we want to analyze\n",
    "ylabels = df['class'] # the labels, or answers, we want to test against\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
=======
      "cell_type": "markdown",
      "source": [
        "# Doc2Vec"
      ],
      "metadata": {}
    },
>>>>>>> ac750436c7ed48ab2858a2e41994044fd4bc96d7
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(df, test_size=0.3, random_state=42)\n",
        "lemmatizer = WordNetLemmatizer() \n",
        "\n",
        "def tokenize_text(text):\n",
        "    tokens = []\n",
        "    for sent in nltk.sent_tokenize(text):\n",
        "        for word in nltk.word_tokenize(sent):\n",
        "            if len(word) < 2:\n",
        "                continue\n",
        "            tokens.append(lemmatizer.lemmatize(word.lower()))\n",
        "    return tokens\n",
        "\n",
        "train_tagged = train.apply(\n",
        "    lambda r: TaggedDocument(words=tokenize_text(r['clean_lyrics']), tags=[r['class']]), axis=1)\n",
        "test_tagged = test.apply(\n",
        "    lambda r: TaggedDocument(words=tokenize_text(r['clean_lyrics']), tags=[r['class']]), axis=1)"
      ],
      "outputs": [],
      "execution_count": 6,
      "metadata": {}
    },
    {
<<<<<<< HEAD
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test Accuracy: 0.5348980852378011\n",
      " Precision: [0.5007215  0.56047516]\n",
      " Recall: [0.4602122 0.6      ]\n"
     ]
    }
   ],
   "source": [
    "classifier = RandomForestClassifier(n_estimators=1000)\n",
    "\n",
    "# Create pipeline using Bag of Words\n",
    "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
    "                 ('classifier', classifier)])\n",
    "\n",
    "# model generation\n",
    "pipe.fit(X_train,y_train)\n",
    "\n",
    "from sklearn import metrics\n",
    "# Predicting with a test dataset\n",
    "predicted = pipe.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\" test Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
    "print(\" Precision:\",metrics.precision_score(y_test, predicted, average=None))\n",
    "print(\" Recall:\",metrics.recall_score(y_test, predicted, average=None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Audio Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_features = ['acousticness', 'danceability',  'energy',\n",
    "            'instrumentalness', 'liveness', 'loudness', 'mode',\n",
    "            'speechiness', 'tempo', 'time_signature', 'valence']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[audio_features]\n",
    "y = df['class']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3, random_state=72)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "acousticness          0.241923\n",
       "danceability          0.614023\n",
       "energy                0.635110\n",
       "instrumentalness      0.032694\n",
       "liveness              0.171027\n",
       "loudness             -8.884228\n",
       "mode                  0.707005\n",
       "speechiness           0.061580\n",
       "tempo               120.103809\n",
       "time_signature        3.960341\n",
       "valence               0.603625\n",
       "dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test Accuracy: 0.5941939468807906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkrsteska/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "predicted = classifier.predict(X_test)\n",
    "print(\" test Accuracy:\",metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>loudness</th>\n",
       "      <th>mode</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>time_signature</th>\n",
       "      <th>valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.18400</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.132</td>\n",
       "      <td>-4.333</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0300</td>\n",
       "      <td>104.988</td>\n",
       "      <td>4</td>\n",
       "      <td>0.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.46300</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.469</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.103</td>\n",
       "      <td>-7.226</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>98.963</td>\n",
       "      <td>4</td>\n",
       "      <td>0.631</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.85600</td>\n",
       "      <td>0.607</td>\n",
       "      <td>0.376</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.285</td>\n",
       "      <td>-9.954</td>\n",
       "      <td>1</td>\n",
       "      <td>0.4530</td>\n",
       "      <td>102.541</td>\n",
       "      <td>4</td>\n",
       "      <td>0.545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.00165</td>\n",
       "      <td>0.548</td>\n",
       "      <td>0.889</td>\n",
       "      <td>0.001090</td>\n",
       "      <td>0.197</td>\n",
       "      <td>-4.682</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>90.048</td>\n",
       "      <td>4</td>\n",
       "      <td>0.425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.47800</td>\n",
       "      <td>0.398</td>\n",
       "      <td>0.366</td>\n",
       "      <td>0.060900</td>\n",
       "      <td>0.223</td>\n",
       "      <td>-15.276</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0310</td>\n",
       "      <td>70.779</td>\n",
       "      <td>4</td>\n",
       "      <td>0.560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      acousticness  danceability  energy  instrumentalness  liveness  \\\n",
       "0          0.18400         0.765   0.523          0.000036     0.132   \n",
       "1          0.46300         0.731   0.469          0.000001     0.103   \n",
       "10         0.85600         0.607   0.376          0.000000     0.285   \n",
       "100        0.00165         0.548   0.889          0.001090     0.197   \n",
       "1000       0.47800         0.398   0.366          0.060900     0.223   \n",
       "\n",
       "      loudness  mode  speechiness    tempo  time_signature  valence  \n",
       "0       -4.333     1       0.0300  104.988               4    0.394  \n",
       "1       -7.226     1       0.0326   98.963               4    0.631  \n",
       "10      -9.954     1       0.4530  102.541               4    0.545  \n",
       "100     -4.682     1       0.0382   90.048               4    0.425  \n",
       "1000   -15.276     1       0.0310   70.779               4    0.560  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mkrsteska/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " test Accuracy: 0.6145768993205682\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "poly = PolynomialFeatures(2)\n",
    "X_train = poly.fit_transform(X_train)\n",
    "\n",
    "X_test = poly.transform(X_test)\n",
    "\n",
    "classifier = LogisticRegression()\n",
    "classifier.fit(X_train, y_train)\n",
    "predicted = classifier.predict(X_test)\n",
    "print(\" test Accuracy:\",metrics.accuracy_score(y_test, predicted))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
=======
      "cell_type": "code",
      "source": [
        "train_tagged.values[1]"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 7,
          "data": {
            "text/plain": [
              "TaggedDocument(words=['today', 'do', 'not', 'feel', 'like', 'doing', 'anything', 'just', 'wan', 'na', 'lay', 'in', 'my', 'bed', 'do', 'not', 'feel', 'like', 'picking', 'up', 'my', 'phone', 'so', 'leave', 'message', 'at', 'the', 'tone', 'because', 'today', 'swear', 'am', 'not', 'doing', 'anything', 'am', 'going', 'to', 'kick', 'my', 'foot', 'up', 'then', 'stare', 'at', 'the', 'fan', 'turn', 'the', 'tv', 'on', 'throw', 'my', 'hand', 'in', 'my', 'pant', 'nobody', 'going', 'to', 'tell', 'me', 'can', 'not', 'will', 'be', 'lounging', 'on', 'the', 'couch', 'just', 'chillin', 'in', 'my', 'snuggie', 'click', 'to', 'mtv', 'so', 'they', 'can', 'teach', 'me', 'how', 'to', 'dougie', 'because', 'in', 'my', 'castle', 'am', 'the', 'freaking', 'man', 'oh', 'oh', 'yes', 'said', 'it', 'said', 'it', 'said', 'it', 'because', 'can', 'today', 'do', 'not', 'feel', 'like', 'doing', 'anything', 'just', 'wan', 'na', 'lay', 'in', 'my', 'bed', 'do', 'not', 'feel', 'like', 'picking', 'up', 'my', 'phone', 'so', 'leave', 'message', 'at', 'the', 'tone', 'because', 'today', 'swear', 'am', 'not', 'doing', 'anything', 'nothing', 'at', 'all', 'nothing', 'at', 'all', 'tomorrow', 'will', 'wake', 'up', 'do', 'some', 'p90x', 'meet', 'really', 'nice', 'girl', 'have', 'some', 'really', 'nice', 'sex', 'she', 'is', 'going', 'to', 'scream', 'out', 'this', 'is', 'great', 'yeah', 'might', 'mess', 'around', 'and', 'get', 'my', 'college', 'degree', 'bet', 'my', 'old', 'man', 'will', 'be', 'so', 'proud', 'of', 'me', 'but', 'sorry', 'pop', 'you', 'will', 'just', 'have', 'to', 'wait', 'oh', 'oh', 'yes', 'said', 'it', 'said', 'it', 'said', 'it', 'because', 'can', 'today', 'do', 'not', 'feel', 'like', 'doing', 'anything', 'just', 'wan', 'na', 'lay', 'in', 'my', 'bed', 'do', 'not', 'feel', 'like', 'picking', 'up', 'my', 'phone', 'so', 'leave', 'message', 'at', 'the', 'tone', 'because', 'today', 'swear', 'am', 'not', 'doing', 'anything', 'no', 'am', 'not', 'going', 'to', 'comb', 'my', 'hair', 'because', 'am', 'not', 'going', 'anywhere', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'no', 'will', 'just', 'strut', 'in', 'my', 'birthday', 'suit', 'and', 'let', 'everything', 'hang', 'loose', 'yeah', 'yeah', 'yeah', 'yeah', 'yeah', 'yeah', 'yeah', 'yeah', 'yeah', 'yeah', 'oh', 'today', 'do', 'not', 'feel', 'like', 'doing', 'anything', 'just', 'wan', 'na', 'lay', 'in', 'my', 'bed', 'do', 'not', 'feel', 'like', 'picking', 'up', 'my', 'phone', 'so', 'leave', 'message', 'at', 'the', 'tone', 'because', 'today', 'swear', 'am', 'not', 'doing', 'anything', 'nothing', 'at', 'all', 'nothing', 'at', 'all'], tags=[1])"
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 7,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "cores = multiprocessing.cpu_count()"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "model_dbow = Doc2Vec(dm=0, vector_size=100, negative=5, hs=0, min_count=2, sample = 0, workers=cores)\n",
        "model_dbow.build_vocab([x for x in tqdm(train_tagged.values)])"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3777/3777 [00:00<00:00, 1037247.84it/s]\n"
          ]
        }
      ],
      "execution_count": 9,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "%%time\n",
        "for epoch in range(30):\n",
        "    model_dbow.train(utils.shuffle([x for x in tqdm(train_tagged.values)]), total_examples=len(train_tagged.values), epochs=1)\n",
        "    model_dbow.alpha -= 0.002\n",
        "    model_dbow.min_alpha = model_dbow.alpha"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 3777/3777 [00:00<00:00, 905923.61it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 1556636.16it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 2582635.51it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 1381760.68it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 1899962.37it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 1574896.73it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 2372960.79it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 1343557.48it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 2397742.73it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 2532270.81it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 2408679.67it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 1345154.64it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 1805137.44it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 2266040.08it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 2413817.80it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 2515783.10it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 1547512.57it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 2347989.66it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 2691451.96it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 1180820.38it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 1839299.46it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 1566952.15it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 620544.72it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 2392672.74it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 2369057.31it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 2406849.93it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 1874335.80it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 2219373.24it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 2102719.17it/s]\n",
            "100%|██████████| 3777/3777 [00:00<00:00, 2776355.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CPU times: user 59.3 s, sys: 954 ms, total: 1min\n",
            "Wall time: 21.7 s\n"
          ]
        }
      ],
      "execution_count": 10,
      "metadata": {
        "scrolled": true
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def vec_for_learning(model, tagged_docs):\n",
        "    sents = tagged_docs.values\n",
        "    targets, regressors = zip(*[(doc.tags[0], model.infer_vector(doc.words, steps=20)) for doc in sents])\n",
        "    return targets, regressors"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "y_train, X_train = vec_for_learning(model_dbow, train_tagged)\n",
        "y_test, X_test = vec_for_learning(model_dbow, test_tagged)\n",
        "logreg = LogisticRegression(n_jobs=1, C=1e5)\n",
        "logreg.fit(X_train, y_train)\n",
        "y_pred = logreg.predict(X_test)\n",
        "print('Testing accuracy %s' % accuracy_score(y_test, y_pred))\n",
        "print('Testing F1 score: {}'.format(f1_score(y_test, y_pred, average='weighted')))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/mkrsteska/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing accuracy 0.5237801111797405\n",
            "Testing F1 score: 0.5223994123328256\n"
          ]
        }
      ],
      "execution_count": 12,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bag Of Words"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from spacy.lang.en import English\n",
        "\n",
        "# Create our list of punctuation marks\n",
        "punctuations = string.punctuation\n",
        "\n",
        "# Create our list of stopwords\n",
        "nlp = spacy.load('en')\n",
        "stop_words = spacy.lang.en.stop_words.STOP_WORDS\n",
        "\n",
        "# Load English tokenizer, tagger, parser, NER and word vectors\n",
        "parser = English()\n",
        "\n",
        "# Creating our tokenizer function\n",
        "def spacy_tokenizer(sentence):\n",
        "    # Creating our token object, which is used to create documents with linguistic annotations.\n",
        "    mytokens = parser(sentence)\n",
        "\n",
        "    # Lemmatizing each token and converting each token into lowercase\n",
        "    mytokens = [ word.lemma_.lower().strip() if word.lemma_ != \"-PRON-\" else word.lower_ for word in mytokens ]\n",
        "\n",
        "    # Removing stop words\n",
        "    mytokens = [ word for word in mytokens if word not in stop_words and word not in punctuations ]\n",
        "\n",
        "    # return preprocessed list of tokens\n",
        "    return mytokens"
      ],
      "outputs": [],
      "execution_count": 13,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "tfidf_vector = TfidfVectorizer(tokenizer = spacy_tokenizer)"
      ],
      "outputs": [],
      "execution_count": 14,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "X = df['clean_lyrics'] # the features we want to analyze\n",
        "ylabels = df['class'] # the labels, or answers, we want to test against\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3, random_state=72)"
      ],
      "outputs": [],
      "execution_count": 15,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = LogisticRegression(solver=\"lbfgs\")\n",
        "\n",
        "# Create pipeline using Bag of Words\n",
        "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "# model generation\n",
        "pipe.fit(X_train,y_train)\n",
        "\n",
        "from sklearn import metrics\n",
        "# Predicting with a test dataset\n",
        "predicted = pipe.predict(X_test)\n",
        "\n",
        "# Model Accuracy\n",
        "print(\" test Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
        "print(\" Precision:\",metrics.precision_score(y_test, predicted, average=None))\n",
        "print(\" Recall:\",metrics.recall_score(y_test, predicted, average=None))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " test Accuracy: 0.5497220506485485\n",
            " Precision: [0.51548947 0.58374384]\n",
            " Recall: [0.55172414 0.54797688]\n"
          ]
        }
      ],
      "execution_count": 16,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = RandomForestClassifier(n_estimators=1000)\n",
        "\n",
        "# Create pipeline using Bag of Words\n",
        "pipe = Pipeline([('vectorizer', tfidf_vector),\n",
        "                 ('classifier', classifier)])\n",
        "\n",
        "# model generation\n",
        "pipe.fit(X_train,y_train)\n",
        "\n",
        "from sklearn import metrics\n",
        "# Predicting with a test dataset\n",
        "predicted = pipe.predict(X_test)\n",
        "\n",
        "# Model Accuracy\n",
        "print(\" test Accuracy:\",metrics.accuracy_score(y_test, predicted))\n",
        "print(\" Precision:\",metrics.precision_score(y_test, predicted, average=None))\n",
        "print(\" Recall:\",metrics.recall_score(y_test, predicted, average=None))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " test Accuracy: 0.5262507720815318\n",
            " Precision: [0.490701   0.55326087]\n",
            " Recall: [0.45490716 0.58843931]\n"
          ]
        }
      ],
      "execution_count": 17,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Audio Features"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "audio_features = ['acousticness', 'danceability',  'energy',\n",
        "            'instrumentalness', 'liveness', 'loudness', 'mode',\n",
        "            'speechiness', 'tempo', 'time_signature', 'valence']"
      ],
      "outputs": [],
      "execution_count": 18,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "X = df[audio_features]\n",
        "y = df['class']\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, ylabels, test_size=0.3, random_state=72)"
      ],
      "outputs": [],
      "execution_count": 19,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "classifier = LogisticRegression()\n",
        "classifier.fit(X_train, y_train)\n",
        "predicted = classifier.predict(X_test)\n",
        "print(\" test Accuracy:\",metrics.accuracy_score(y_test, predicted))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " test Accuracy: 0.5941939468807906\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/home/mkrsteska/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
            "  FutureWarning)\n"
          ]
        }
      ],
      "execution_count": 20,
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "X.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 21,
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>acousticness</th>\n",
              "      <th>danceability</th>\n",
              "      <th>energy</th>\n",
              "      <th>instrumentalness</th>\n",
              "      <th>liveness</th>\n",
              "      <th>loudness</th>\n",
              "      <th>mode</th>\n",
              "      <th>speechiness</th>\n",
              "      <th>tempo</th>\n",
              "      <th>time_signature</th>\n",
              "      <th>valence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.18400</td>\n",
              "      <td>0.765</td>\n",
              "      <td>0.523</td>\n",
              "      <td>0.000036</td>\n",
              "      <td>0.132</td>\n",
              "      <td>-4.333</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0300</td>\n",
              "      <td>104.988</td>\n",
              "      <td>4</td>\n",
              "      <td>0.394</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.46300</td>\n",
              "      <td>0.731</td>\n",
              "      <td>0.469</td>\n",
              "      <td>0.000001</td>\n",
              "      <td>0.103</td>\n",
              "      <td>-7.226</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0326</td>\n",
              "      <td>98.963</td>\n",
              "      <td>4</td>\n",
              "      <td>0.631</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0.85600</td>\n",
              "      <td>0.607</td>\n",
              "      <td>0.376</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.285</td>\n",
              "      <td>-9.954</td>\n",
              "      <td>1</td>\n",
              "      <td>0.4530</td>\n",
              "      <td>102.541</td>\n",
              "      <td>4</td>\n",
              "      <td>0.545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>0.00165</td>\n",
              "      <td>0.548</td>\n",
              "      <td>0.889</td>\n",
              "      <td>0.001090</td>\n",
              "      <td>0.197</td>\n",
              "      <td>-4.682</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0382</td>\n",
              "      <td>90.048</td>\n",
              "      <td>4</td>\n",
              "      <td>0.425</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1000</th>\n",
              "      <td>0.47800</td>\n",
              "      <td>0.398</td>\n",
              "      <td>0.366</td>\n",
              "      <td>0.060900</td>\n",
              "      <td>0.223</td>\n",
              "      <td>-15.276</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0310</td>\n",
              "      <td>70.779</td>\n",
              "      <td>4</td>\n",
              "      <td>0.560</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      acousticness  danceability  energy  instrumentalness  liveness  \\\n",
              "0          0.18400         0.765   0.523          0.000036     0.132   \n",
              "1          0.46300         0.731   0.469          0.000001     0.103   \n",
              "10         0.85600         0.607   0.376          0.000000     0.285   \n",
              "100        0.00165         0.548   0.889          0.001090     0.197   \n",
              "1000       0.47800         0.398   0.366          0.060900     0.223   \n",
              "\n",
              "      loudness  mode  speechiness    tempo  time_signature  valence  \n",
              "0       -4.333     1       0.0300  104.988               4    0.394  \n",
              "1       -7.226     1       0.0326   98.963               4    0.631  \n",
              "10      -9.954     1       0.4530  102.541               4    0.545  \n",
              "100     -4.682     1       0.0382   90.048               4    0.425  \n",
              "1000   -15.276     1       0.0310   70.779               4    0.560  "
            ]
          },
          "metadata": {}
        }
      ],
      "execution_count": 21,
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.3",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "0.15.0"
    }
>>>>>>> ac750436c7ed48ab2858a2e41994044fd4bc96d7
  },
  "nbformat": 4,
  "nbformat_minor": 2
}